{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3920fd",
   "metadata": {},
   "source": [
    "# Text Data Representation (Text Preprocessing)\n",
    "\n",
    "Text data representation in NLP (Natural Language Processing) refers to the process of converting raw text into a structured and numerical format that can be understood and processed by machine learning algorithms or other NLP models. Since machines primarily work with numerical data, text data representation is essential for extracting meaningful information and patterns from textual content.\n",
    "\n",
    "There are different approaches for representing text data in NLP, including:\n",
    "\n",
    "1. **Bag-of-Words (BoW)**: The BoW representation treats each document as a collection of words and creates a vector representation based on the frequency or presence of words in the document. It disregards the order or sequence of words and represents text as a set of word occurrences or frequencies.\n",
    "\n",
    "2. **Term Frequency-Inverse Document Frequency (TF-IDF)**: TF-IDF is a weighted representation that assigns a score to each word based on its frequency in a document and its rarity across the entire corpus. It emphasizes words that are frequent in a document but rare in the overall corpus, capturing their relative importance.\n",
    "\n",
    "3. **Word Embeddings**: Word embeddings are dense, low-dimensional vector representations that capture semantic and contextual relationships between words. Models like Word2Vec, GloVe, and FastText learn to represent words in a continuous vector space, capturing their meaning and similarity.\n",
    "\n",
    "4. **Neural Network-based representations**: Deep learning models, such as recurrent neural networks (RNNs) or transformers, can learn contextual representations of words or documents. They leverage the sequential or hierarchical structure of the text to capture dependencies and generate dense vector representations.\n",
    "\n",
    "5. **Character-level representations**: Instead of focusing on words, character-level representations operate at the individual character level. This approach can capture morphological or spelling variations and is useful for tasks like text generation or sentiment analysis.\n",
    "\n",
    "**Note:** The choice of representation depends on the specific task, dataset size, language complexity, and available resources. Effective text data representation enables NLP models to extract meaningful information, perform tasks such as text classification, sentiment analysis, machine translation, information extraction, and facilitate the understanding and analysis of textual content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148a6b77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:38.939557Z",
     "start_time": "2023-07-24T09:37:38.934799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# seeding\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f086ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:38.985003Z",
     "start_time": "2023-07-24T09:37:38.944310Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "data = pd.read_csv('../Data/swahili_news_titles_clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977c9293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:38.992075Z",
     "start_time": "2023-07-24T09:37:38.986983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kiongozi wawili kikaangoni</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ruangwa yafanya kweli miradi maji</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marekani yaishuku urusi kukiuka mkataba nyuklia</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watumishi umma kuula</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ccm yatoa siri ushindi uchaguzi</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         headlines  word_count\n",
       "0                       kiongozi wawili kikaangoni           3\n",
       "1                ruangwa yafanya kweli miradi maji           5\n",
       "2  marekani yaishuku urusi kukiuka mkataba nyuklia           6\n",
       "3                             watumishi umma kuula           3\n",
       "4                  ccm yatoa siri ushindi uchaguzi           5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show sample of the data\n",
    "\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cddd44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-26T06:25:06.879972Z",
     "start_time": "2023-05-26T06:25:06.831672Z"
    }
   },
   "source": [
    "##  1. Bag of word (BoW)\n",
    "\n",
    "The Bag-of-Words (BoW) is a fundamental concept in Natural Language Processing (NLP) used to represent text documents as numerical feature vectors. It involves creating a vocabulary of unique words in the corpus and then quantifying the presence or frequency of these words in each document. The order or grammar of the words is disregarded, and only the occurrence information is considered. By representing documents as a collection of word counts or frequencies.\n",
    "\n",
    "BoW enables machines to process and analyze text data using numerical methods and algorithms. It serves as a basis for various NLP tasks such as text classification, sentiment analysis, topic modeling, and information retrieval.\n",
    "\n",
    "## How to implement in Python?\n",
    "\n",
    "\n",
    "To implement the Bag-of-Words (BoW) representation in Python, you can utilize the CountVectorizer class from the scikit-learn library. \n",
    "\n",
    "The Count Vectorizer transforms a string into a Frequency representation.It tokenizes the text and applies basic and elementary processing.\n",
    "\n",
    "The objective is to make a vector with as many dimensions as there are distinct words. Each unique word has its own dimension, which will be represented by 1 in that dimension and 0 in all others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7cede0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:39.004758Z",
     "start_time": "2023-07-24T09:37:38.994906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  document  first  is  one  second  the  third  this\n",
       "0    0         1      1   1    0       0    1      0     1\n",
       "1    0         2      0   1    0       1    1      0     1\n",
       "2    1         0      0   1    1       0    1      1     1\n",
       "3    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick example\n",
    "text = [\n",
    "    'This is the first document', 'This document is the second document',\n",
    "    'And this is the third one', 'is this the first document',\n",
    "]\n",
    "\n",
    "coun_vect = CountVectorizer()\n",
    "count_matrix = coun_vect.fit_transform(text)\n",
    "count_array = count_matrix.toarray()\n",
    "df = pd.DataFrame(data=count_array, columns=coun_vect.get_feature_names_out())\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5809f8eb",
   "metadata": {},
   "source": [
    "### Implement CountVectorizer method in the Swahili News headlines dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99d16e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:39.224829Z",
     "start_time": "2023-07-24T09:37:39.006870Z"
    }
   },
   "outputs": [],
   "source": [
    "# how to implement using countvectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# fit and transform the data with count vectorizer\n",
    "count_data = count_vectorizer.fit_transform(data['headlines'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d777a9f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:39.229005Z",
     "start_time": "2023-07-24T09:37:39.225907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the transformed data\n",
    "\n",
    "count_data[:10].toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "486c8633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:39.584025Z",
     "start_time": "2023-07-24T09:37:39.229971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aacha</th>\n",
       "      <th>aachana</th>\n",
       "      <th>aachane</th>\n",
       "      <th>aache</th>\n",
       "      <th>aachia</th>\n",
       "      <th>aachie</th>\n",
       "      <th>aachiliwa</th>\n",
       "      <th>aachiwa</th>\n",
       "      <th>aachiwe</th>\n",
       "      <th>...</th>\n",
       "      <th>zuku</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zumbukuku</th>\n",
       "      <th>zungu</th>\n",
       "      <th>zuri</th>\n",
       "      <th>zutah</th>\n",
       "      <th>zutta</th>\n",
       "      <th>zuttah</th>\n",
       "      <th>zverev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22015 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aacha  aachana  aachane  aache  aachia  aachie  aachiliwa  aachiwa  \\\n",
       "0   0      0        0        0      0       0       0          0        0   \n",
       "1   0      0        0        0      0       0       0          0        0   \n",
       "2   0      0        0        0      0       0       0          0        0   \n",
       "3   0      0        0        0      0       0       0          0        0   \n",
       "4   0      0        0        0      0       0       0          0        0   \n",
       "\n",
       "   aachiwe  ...  zuku  zulu  zuma  zumbukuku  zungu  zuri  zutah  zutta  \\\n",
       "0        0  ...     0     0     0          0      0     0      0      0   \n",
       "1        0  ...     0     0     0          0      0     0      0      0   \n",
       "2        0  ...     0     0     0          0      0     0      0      0   \n",
       "3        0  ...     0     0     0          0      0     0      0      0   \n",
       "4        0  ...     0     0     0          0      0     0      0      0   \n",
       "\n",
       "   zuttah  zverev  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "\n",
       "[5 rows x 22015 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get features names\n",
    "cv_feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "# create dataframe for the transformed data\n",
    "count_data_df = pd.DataFrame(count_data.toarray(),\n",
    "                             columns=list(cv_feature_names))\n",
    "\n",
    "# view top 5 rows\n",
    "count_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56806f96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:39.587655Z",
     "start_time": "2023-07-24T09:37:39.585224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31024, 22015)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape \n",
    "count_data_df.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496588d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-26T06:32:45.957021Z",
     "start_time": "2023-05-26T06:32:45.712849Z"
    }
   },
   "source": [
    "## 2. Term Frequency-Inverse Document Frequency (TF-IDF):\n",
    "\n",
    "Term Frequency-Inverse Document Frequency (TF-IDF) is a numerical representation technique used in Natural Language Processing (NLP) to measure the importance of words in a document. It takes into account two factors:\n",
    "    \n",
    "- Term frequency(TF)\n",
    "- Inverse document frequency. \n",
    "\n",
    "\n",
    "**(a) Term frequency**: It represents how often a word appears in a document. \n",
    "\n",
    "**(b) Inverse document frequency**: It measures how rare a word is across all documents in a collection.\n",
    "    \n",
    "TF-IDF assigns higher weights to words that occur frequently within a specific document but are less common in the overall document collection. This allows TF-IDF to highlight words that are both important within a document and distinct across the entire corpus. By calculating TF-IDF values for each word, NLP models can capture the relative significance of words and use them for tasks like information retrieval, text classification, and document ranking.\n",
    "\n",
    "### Mathematical Formula \n",
    "TF-IDF has two-part:\n",
    "\n",
    "1. TF = Number of repetition of words in a sentence / Number of words in a sentence\n",
    "2. IDF = log( Number of sentences / Number of sentences containing the word)\n",
    "\n",
    "TF-IDF Terminology:\n",
    "- T = Term (word)\n",
    "- F = Frequency\n",
    "- D = Document (set of word)\n",
    "\n",
    "TF-IDF = Term Frequency (TF) * Inverse Document Frequency (IDF)\n",
    "\n",
    "![](https://media.licdn.com/dms/image/C5612AQFcV0nH5A23ow/article-inline_image-shrink_1000_1488/0/1626417114643?e=1690416000&v=beta&t=RuKyVENGafUleFdv1S8EWUeqyooxWF2ZS3ql5FoIjcY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac42fb1",
   "metadata": {},
   "source": [
    "### How to implement in Python?\n",
    "\n",
    "To implement Term Frequency-Inverse Document Frequency (TF-IDF) in Python, you can use the TfidfVectorizer class from the scikit-learn.\n",
    "\n",
    "The TfidfVectorizer class to convert the text documents into a matrix of TF-IDF values. The fit_transform method fits the TfidfVectorizer on the corpus and transforms the documents into their TF-IDF representations.\n",
    "\n",
    "Finally, you can access the feature names and the TF-IDF representation of each document using get_feature_names() and toarray() methods, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5d98df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:39.600227Z",
     "start_time": "2023-07-24T09:37:39.590033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538648</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267104</td>\n",
       "      <td>0.511849</td>\n",
       "      <td>0.267104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>0.580286</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  document     first        is       one    second       the  \\\n",
       "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
       "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
       "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
       "\n",
       "      third      this  \n",
       "0  0.000000  0.384085  \n",
       "1  0.000000  0.281089  \n",
       "2  0.511849  0.267104  \n",
       "3  0.000000  0.384085  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick example\n",
    "text = [\n",
    "    'This is the first document', 'This document is the second document',\n",
    "    'And this is the third one', 'is this the first document',\n",
    "]\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,1))\n",
    "tfidf_matrix = tfidf_vect.fit_transform(text)\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "df = pd.DataFrame(data=tfidf_array, columns=tfidf_vect.get_feature_names_out())\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37e66d8",
   "metadata": {},
   "source": [
    "### Implement TfidfVectorizer method in the Swahili News headlines dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab14b3c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:39.842874Z",
     "start_time": "2023-07-24T09:37:39.602288Z"
    }
   },
   "outputs": [],
   "source": [
    "# how to implement using TFIDF Vectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit and transform the data with tfidf vectorizer\n",
    "tfidf_data = tfidf_vectorizer.fit_transform(data['headlines'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e3e448a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:39.847332Z",
     "start_time": "2023-07-24T09:37:39.844237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the transformed data\n",
    "\n",
    "tfidf_data[:10].toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffc8992a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:40.274199Z",
     "start_time": "2023-07-24T09:37:39.848440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aacha</th>\n",
       "      <th>aachana</th>\n",
       "      <th>aachane</th>\n",
       "      <th>aache</th>\n",
       "      <th>aachia</th>\n",
       "      <th>aachie</th>\n",
       "      <th>aachiliwa</th>\n",
       "      <th>aachiwa</th>\n",
       "      <th>aachiwe</th>\n",
       "      <th>...</th>\n",
       "      <th>zuku</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zumbukuku</th>\n",
       "      <th>zungu</th>\n",
       "      <th>zuri</th>\n",
       "      <th>zutah</th>\n",
       "      <th>zutta</th>\n",
       "      <th>zuttah</th>\n",
       "      <th>zverev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22015 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aacha  aachana  aachane  aache  aachia  aachie  aachiliwa  aachiwa  \\\n",
       "0  0.0    0.0      0.0      0.0    0.0     0.0     0.0        0.0      0.0   \n",
       "1  0.0    0.0      0.0      0.0    0.0     0.0     0.0        0.0      0.0   \n",
       "2  0.0    0.0      0.0      0.0    0.0     0.0     0.0        0.0      0.0   \n",
       "3  0.0    0.0      0.0      0.0    0.0     0.0     0.0        0.0      0.0   \n",
       "4  0.0    0.0      0.0      0.0    0.0     0.0     0.0        0.0      0.0   \n",
       "\n",
       "   aachiwe  ...  zuku  zulu  zuma  zumbukuku  zungu  zuri  zutah  zutta  \\\n",
       "0      0.0  ...   0.0   0.0   0.0        0.0    0.0   0.0    0.0    0.0   \n",
       "1      0.0  ...   0.0   0.0   0.0        0.0    0.0   0.0    0.0    0.0   \n",
       "2      0.0  ...   0.0   0.0   0.0        0.0    0.0   0.0    0.0    0.0   \n",
       "3      0.0  ...   0.0   0.0   0.0        0.0    0.0   0.0    0.0    0.0   \n",
       "4      0.0  ...   0.0   0.0   0.0        0.0    0.0   0.0    0.0    0.0   \n",
       "\n",
       "   zuttah  zverev  \n",
       "0     0.0     0.0  \n",
       "1     0.0     0.0  \n",
       "2     0.0     0.0  \n",
       "3     0.0     0.0  \n",
       "4     0.0     0.0  \n",
       "\n",
       "[5 rows x 22015 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get features names\n",
    "cv_feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "# create dataframe for the transformed data\n",
    "tfidf_data_df = pd.DataFrame(tfidf_data.toarray(),\n",
    "                             columns=list(cv_feature_names))\n",
    "\n",
    "# view top 5 rows\n",
    "tfidf_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfc690d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T09:37:40.279240Z",
     "start_time": "2023-07-24T09:37:40.275516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31024, 22015)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape \n",
    "tfidf_data_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f66efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a859151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
